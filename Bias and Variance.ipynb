{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bias-Variance分解"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一、基本原理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "假定的真实模型为$$ y = f(x) + \\epsilon ,$$其中$E(\\epsilon)=0,V(\\epsilon)={\\sigma}^{2}.$\n",
    "\n",
    "\n",
    "对给定训练集$\\{(x_{i},y_{i})\\}$下训练出的假设$h(x)=ax+b$，我们通过预测误差$E_{P}{(y^{*}-h(x^{*}))}^{2}$对其进行评价\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二、基本思路及待讨论解决问题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们假定训练集样本点的概率分布满足$E_{P}[Z]=\\underline{Z}$,于是\n",
    "$$\n",
    "\\begin{split}\n",
    "& E_{P}{(y^{*}-h(x^{*}))}^{2}\\\\\n",
    "= & E[{(h(x^{*})-\\underline{h(x^{*})})}^{2}] + {[\\underline{h(x^{*})}-f(x^{*})]}^{2} +  E[{(y^{*}-f(x^{*}))}^{2}]\\\\ \n",
    "= & Variance + Bias^{2} + Noise\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "然后用足够多的训练样本点$(x_i^*,y_i^*)$去评价假设$h(x)$，对每个给定的$(x_i^*,y_i^*)$，有\n",
    "\n",
    "$$Variance_i = E[{(h(x_i^*)-\\underline{h(x_i^*)})}^{2}]$$\n",
    "\n",
    "$$Bias_i^2 = {[\\underline{h(x_i^{*})}-f(x_i^{*})]}^{2}$$\n",
    "\n",
    "于是我们可以得到对假定模型$h(x)=ax+b$最终的评价\n",
    "\n",
    "$$Bias^2 = E[E[{(h(x_i^*)-\\underline{h(x_i^*)})}^{2}]]$$\n",
    "\n",
    "$$Variance = E[{[\\underline{h(x_i^{*})}-f(x_i^{*})]}^{2}]$$\n",
    "\n",
    "\n",
    "下面我们用程序来完成这个过程，并在这个基础上讨论**当误差项$\\epsilon$的方差${\\sigma}^{2}$变化时，$h(x)$复杂度的选择问题**。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 三、代码部分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 代码思路"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "真实函数$$ y = 2{e}^x + \\epsilon ,$$其中$\\epsilon\\sim N(0,\\sigma^2)$。对$f(x) = 2{e}^x$进行泰勒展开，有$$f(x) = 2{e}^x = 2x + 2x^2 + 2x^3 + ...$$\n",
    "\n",
    "于是选择不同光滑度的函数h(x)进行训练，下列公式光滑度由低到高：\n",
    " $$h(x)_1 = a_1x+b$$\n",
    " $$h(x)_2 = a_1x+a_2x^2 + b$$\n",
    " $$h(x)_3 = a_1x+a_2x^2+a_3x^3+b$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 代码内容"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### （1）自定义函数lml\n",
    "- 函数$lml$的输入为训练集TR与测试集TE，输出为以TR为训练集训练出的$h(x)$关于TE的预测集。\n",
    "\n",
    "- TR为训练集，TE为测试集，TR和TE变量结构相同，第一个为因变量\n",
    "\n",
    "- mlm以向前法的顺序，添加自变量，建立相应的回归模型，并给出与之对应的TE的因变量的预测值\n",
    "\n",
    "- 预测结果排列为1个向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立回归函数mlm，返回 x 逐步进入的测试集的预测值y\n",
    "mlm <- function(TR, TE){    # dataframe\n",
    "  vname = names(TR)   # 变量名\n",
    "  yn=vname[1]         # 因变量名称 y\n",
    "  xn=vname[-1]        # 自变量名称 xn = c(x1,x2,x3,x4)\n",
    "  mp=length(xn)       # 自变量的维数\n",
    "\n",
    "  ypr=NULL # 预测值\n",
    "  tm=paste(yn,xn[1],sep=\"~\")     # 将因变量y和第一个自变量粘贴成y~x.1的形式，建立lm函数。\n",
    "  fam=formula(tm)                # 公式化\n",
    "  # 开始循环，cp为指针，从第一个自变量开始\n",
    "  cp=1  \n",
    "  repeat{\n",
    "    lm1 = lm(fam,TR)             # 运用公式化后的lm函数对训练集TR做回归，得到相应的回归系数。\n",
    "    ypr=c(ypr,predict(lm1,TE))   # 给出与之对应的TE的因变量的预测值\n",
    "    \n",
    "    #使用向前法，依次添加自变量x.2、x.3、……、x.p，重新建立lm函数。\n",
    "    if(cp>=mp) break \n",
    "    cp=cp+1 # 加入下一个变量                  \n",
    "    tm=paste(tm,xn[cp],sep=\"+\") #  + xn\n",
    "    fam=formula(tm) \n",
    "  }\n",
    "  as.vector(ypr)                #返回结果为TE的因变量的预测值，其为一个拉直的向量。         \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### （2） 自定义函数BV\n",
    "- 计算**给定光滑度和方差**后得到的**预测函数的偏差bias和方差variance**\n",
    "\n",
    "\n",
    "- 有k个样本量为n的训练集dataTR，与一个样本量为N的测试集dataTE，其中p为做线性回归的自变量的最高阶数，$\\sigma$为随机误差的标准差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(plyr) # plyr包含apply，dpply等函数分隔操作\n",
    "\n",
    "BV <- function(p, sigma, N, n, k){# N样本量，n训练集样本量，k训练集个数\n",
    "  \n",
    "  ##（1）构造两个结构相同的数据集，其中自变量维数均为p，第一个均为因变量 \n",
    "    \n",
    "  # 构造测试集dataTE（样本数为N）\n",
    "  nx <- runif(N,-1,1) # 一个样本数为N的均匀分布的随机数\n",
    "  ny <- 2*exp(nx)+rnorm(N,0,sigma)              #真实函数为y = 2*exp(x)+epsilon 其中epsilon~N(0,sigma^2)\n",
    "  nz <- matrix(nx,N,p)                          #构造一个自变量矩阵，其中自变量维数为p,样本数为N\n",
    "  for(i in 2:p) nz[,i] <- 10*nz[,i]*nz[,i-1]   #乘10为了量纲不要差太多，因为是(0,1)间的，平方会差很多\n",
    "  dataTE <- data.frame(y=ny,z=nz)                  \n",
    "\n",
    "  # 构造训练集dataTR（样本数为n*k）\n",
    "  # (k个训练集，每个训练集的样本量均为n)\n",
    "  x <- runif(n * k,-1,1) \n",
    "  y <- 2 * exp(x) + rnorm(n*k,0,sigma)\n",
    "  z <- matrix(x,n*k,p)                            # ！！！！！！！！！z的长度为n*k，每一列包含k个子集\n",
    "  for(i in 2:p) z[,i]=10*z[,i]*z[,i-1];\n",
    "  dataTR <- data.frame(y=y,z=z)\n",
    "\n",
    "  ## （2）\n",
    "  index <- rep(1:k,rep(n,k)) # 指向属于哪个测试集1--k\n",
    " \n",
    "  ## 使用自定义函数mlm，对样本量为n的训练集dataTR做关于自变量x从1到p阶的线性回归\n",
    "  ## 得到与之对应的关于测试集dataTE的预测。\n",
    "  ## 重复k次，计算偏差和方差。\n",
    "  \n",
    "  # 预测值（   k*(N*p)的矩阵   ）\n",
    "  PRE=daply(dataTR, .(index), mlm, TE = dataTE)     #！！！TE为mlm的参数！！！！\n",
    "                                                    # 也可以写成 index  ，等于.(index)\n",
    "  # 偏差bias\n",
    "  b =  ( apply(PRE,2,mean) - rep(2*exp(nx),p) )^2   # (E(h(x))-f(x))^2\n",
    "  b = matrix(b, nrow=N, byrow=F) # 按列排           # N*p的矩阵，第j列的对应的回归模型的自变量最高阶数为j\n",
    "  b = apply(b, 2, mean)                             # 求不同阶数对应的预测函数的偏差，E[(E(h(x))-f(x))^2]\n",
    "  \n",
    "  # 方差variances\n",
    "  v = apply(PRE, 2, var)                            # var(h(x))\n",
    "  v = matrix(v, nrow=N, byrow=F)                    # 按列排成N*p的矩阵，第j列的对应的回归模型的自变量最高阶数为j\n",
    "  v = apply(v,2,mean)                               # 求不同阶数对应的预测函数的方差，E[var(h(x))]                        \n",
    "  mse= b+v\n",
    "  \n",
    "  list(mse=mse, bias=b, var=v)\n",
    "  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "lm(formula = formula(y ~ x))\n",
       "\n",
       "Coefficients:\n",
       "(Intercept)            x  \n",
       "     0.8455       1.1702  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# \n",
    "x<-rnorm(100)\n",
    "y<-x + 1 + rnorm(100,0,01)\n",
    "lm(formula(y~x))\n",
    "# lm(y~x) 也可以"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           [,1]       [,2]       [,3]        [,4]\n",
      "[1,] -0.6264538 -0.8204684  1.5117812 -0.04493361\n",
      "[2,]  0.1836433  0.4874291  0.3898432 -0.01619026\n",
      "[3,] -0.8356286  0.7383247 -0.6212406  0.94383621\n",
      "[4,]  1.5952808  0.5757814 -2.2146999  0.82122120\n",
      "[5,]  0.3295078 -0.3053884  1.1249309  0.59390132\n",
      "[1] 0.12926990 0.13513567 0.03812297 0.45956697\n",
      "           [,1]       [,2]       [,3] [,4]\n",
      "[1,] -0.6264538 -0.8204684  1.5117812    0\n",
      "[2,]  0.1836433  0.4874291  0.3898432    0\n",
      "[3,] -0.8356286  0.7383247 -0.6212406    0\n",
      "[4,]  1.5952808  0.5757814 -2.2146999    1\n",
      "[5,]  0.3295078 -0.3053884  1.1249309    1\n",
      "x[, 4]: 0\n",
      "[1] -0.4261464\n",
      "------------------------------------------------------------ \n",
      "x[, 4]: 1\n",
      "[1] 0.9623943\n",
      "[1] -0.4261464  0.9623943\n"
     ]
    }
   ],
   "source": [
    "# ！！！！！！不要看\n",
    "set.seed(1)\n",
    "x<-matrix(rnorm(20),5)\n",
    "print(x)\n",
    "# apply可以用矩阵\n",
    "print(apply(x,2,mean))# “2”表明对列\n",
    "\n",
    "x[,4]<-c(0,0,0,1,1)\n",
    "print(x)\n",
    "# by可以用向量\n",
    "print(by(x[,1],x[,4],mean))\n",
    "print(as.vector(unlist(by(x[,1],x[,4],mean))))   # as.vector和unlist非常好用！！！！！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### （3）模型复杂度选取\n",
    "\n",
    "\n",
    "使用自定义函数，分别计算误差项方差$\\sigma^2$为$1^2、5^2和10^2$时，不同光滑度对应预测函数$h(x)$的Bias和Variance，对比不同复杂度下模型的优劣。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 3\n",
      "       msigma\n",
      "[1,] 3      1\n",
      "[2,] 3      5\n",
      "[3,] 3     10\n"
     ]
    }
   ],
   "source": [
    "#定义训练集容量n=500,k个训练集、测试集的容量N=2000、阶数p和sigma的取值\n",
    "N=2000; k=2000; n=500\n",
    "msigma=c(1,5,10)            \n",
    "NL=length(msigma)#　sigma的长度\n",
    "ps=cbind(3,msigma)# 3是变量个数\n",
    "\n",
    "print(NL)# sigma的个数\n",
    "print(ps)# 变量个数，sigma的值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$mse\n",
      "[1] 0.111930994 0.009061599 0.008314926\n",
      "\n",
      "$bias\n",
      "[1] 1.073687e-01 2.922457e-03 5.166725e-05\n",
      "\n",
      "$var\n",
      "[1] 0.004562327 0.006139142 0.008263258\n",
      "\n",
      "$mse\n",
      "[1] 0.2132227 0.1599780 0.2088457\n",
      "\n",
      "$bias\n",
      "[1] 0.1082029051 0.0029466553 0.0001472219\n",
      "\n",
      "$var\n",
      "[1] 0.1050198 0.1570314 0.2086985\n",
      "\n",
      "$mse\n",
      "[1] 0.5214544 0.6285730 0.8204290\n",
      "\n",
      "$bias\n",
      "[1] 0.1011567723 0.0029308874 0.0006573319\n",
      "\n",
      "$var\n",
      "[1] 0.4202976 0.6256421 0.8197717\n",
      "\n",
      "Time difference of 34.07345 secs\n"
     ]
    }
   ],
   "source": [
    "# 计算不同h(x)的bias和variance\n",
    "timestart <- Sys.time() #开始时间\n",
    "\n",
    "# 每一次循环均为给定一个sigma，使用自定义函数BV计算最高阶数为p时的偏差和方差\n",
    "# 一共输出三次，对应不同sigma下的mse、bias、var\n",
    "for(nl in 1:NL) print(BV(ps[nl,1],ps[nl,2], N, n, k)) \n",
    "\n",
    "timeend <- Sys.time()   #结束时间\n",
    "runningtime <- timeend-timestart\n",
    "print(runningtime)      #计算运行时间"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 结论\n",
    "#### 1. 偏差Bias\n",
    "Bias度量了模型预测期望函数和真实函数的偏离程度。  \n",
    "\n",
    "在给定较低的噪声方差$sigma^2$时，**偏差会随着模型复杂度的增加而减少**；  \n",
    "而当噪声方差过高时，模型复杂度的增加会导致预测函数偏离真实函数，即偏差增加。\n",
    "#### 2. 方差Variance\n",
    "Variance表示不同的训练数据集训练出的差异，体现了模型的**稳定性**。  \n",
    "随着模型复杂度的增加，模型的简洁和稳定性均会下降，这体现在方差的增加上。\n",
    "#### 3、AIC\n",
    "AIC体现了模型的**拟合效果**，越小越好。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
